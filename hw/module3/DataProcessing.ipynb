{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this module you will be exposed to the following topics:\n",
    "\n",
    "- Understanding of Data (Data Types and Formats)\n",
    "- Data Collection\n",
    "- Data Cleaning\n",
    "- Data Transforms\n",
    "- Feature Engineering\n",
    "- Outlier Removal Methodologies\n",
    "- FEature Ranking and Selection\n",
    "- Dimensionality Reduction\n",
    "\n",
    "As you begin to utilize these in your data science process it will be important to understand how to put these into a processing pipeline. With machine learning techniques you will need to repeat the same processing steps for your train data and your test data. A processing pipeline allows for sequential processing of your data where the output of each step becomes the input for the next step. The pipeline should be configurable and extensible. \n",
    "\n",
    "You will use the below dataset that is split into train and test and you will implement a data pipeline using at least two processing steps. You may use the built in methods in sklearn for this assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import f\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (120, 4)\n",
      "X_test shape: (30, 4)\n",
      "y_train shape: (120,)\n",
      "y_test shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features\n",
    "y = iris.target  # Target labels\n",
    "\n",
    "# Perform an 80-20 train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting sets to verify the split\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.6, 3.6, 1. , 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [7.1, 3. , 5.9, 2.1]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's place the data in a dataframe for manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(columns=iris.feature_names,data=iris.data)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there any duplicates within the frame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "142                5.8               2.7                5.1               1.9"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df[iris_df.duplicated() == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there is one duplicate at index 142. Let's remove it and see what our dataframe looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "140                6.7               3.1                5.6               2.4\n",
       "141                6.9               3.1                5.1               2.3\n",
       "143                6.8               3.2                5.9               2.3\n",
       "144                6.7               3.3                5.7               2.5\n",
       "145                6.7               3.0                5.2               2.3"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = iris_df.drop_duplicates()\n",
    "iris_df[140:145]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that row 142 has been removed successfully!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can separate per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "sepal_length = iris_df[\"sepal length (cm)\"]\n",
    "sepal_width = iris_df[\"sepal width (cm)\"]\n",
    "petal_length = iris_df[\"petal length (cm)\"]\n",
    "petal_width = iris_df[\"petal length (cm)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the data is beneficial to ensure that each of the features are respresentated on the same scale. This can be very nice to achieve for feature ranking/separation. We can do this using min-max normalization!\n",
    "\n",
    "\\hat{x_{ik}} = \\frac{x_{ik} - min(x_k)}{max(x_k) - min(x_k)} (b-a) +a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_min_max(df, a=0, b=1):\n",
    "    # df: df.DataFrame -> dataset\n",
    "\n",
    "    min_xk = np.min(df.values, axis=0)\n",
    "    max_xk = np.max(df.values, axis=0)\n",
    "\n",
    "    # Min-max normalization\n",
    "    xhat = (df.values - min_xk) / (max_xk - min_xk) * (b-a) + a\n",
    "\n",
    "    normalized_df = pd.DataFrame(data=xhat, columns=df.columns)\n",
    "    return normalized_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = normalize_min_max(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does our new dataset look like after normalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0             0.222222          0.625000           0.067797          0.041667\n",
       "1             0.166667          0.416667           0.067797          0.041667\n",
       "2             0.111111          0.500000           0.050847          0.041667\n",
       "3             0.083333          0.458333           0.084746          0.041667\n",
       "4             0.194444          0.666667           0.067797          0.041667\n",
       "..                 ...               ...                ...               ...\n",
       "144           0.666667          0.416667           0.711864          0.916667\n",
       "145           0.555556          0.208333           0.677966          0.750000\n",
       "146           0.611111          0.416667           0.711864          0.791667\n",
       "147           0.527778          0.583333           0.745763          0.916667\n",
       "148           0.444444          0.416667           0.694915          0.708333\n",
       "\n",
       "[149 rows x 4 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for some outliers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can remove the outliers using Wilk's Outlier Removal:\n",
    "\n",
    "$$ {malanobis}^2 = (x_i - \\mu)\\Sigma^{-1}(x_i - \\mu)^T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal(df_values, alpha=0.01):\n",
    "    # x: feature vector\n",
    "    # df: pd.DataFrame.values -> dataset data\n",
    "    # alpha: sensitivity for outliers\n",
    "    data = deepcopy(df_values)\n",
    "    n = data.shape[0]\n",
    "    p = data.shape[1]\n",
    "\n",
    "    mu = np.mean(data, axis=0, keepdims=True)\n",
    "    #rowvar change since observation are in the rows\n",
    "    cov = np.cov(data, rowvar=False) \n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    # compute the squared malanobis distance, cap the minimum to only positive values\n",
    "    malanobis_dist = np.sqrt(np.maximum((data - mu) @ inv_cov @ (data - mu).T,0)).diagonal()\n",
    "\n",
    "    #compute F-distribution Threshold\n",
    "    f_threshold = f.ppf(1 - alpha, p, n-p) * (p * (n-1) / (n-p))\n",
    "    outliers = malanobis_dist > f_threshold\n",
    "    outliers_removed = data[~outliers]\n",
    "    return outliers_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 4)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = outlier_removal(iris_df.values)\n",
    "outliers.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is no outliers that are present based on Wilk's Outlier Removal and an `alpha = 0.01`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to make a nice helper method to package all the preprocessing steps above. This will make it really nice and easy to transform the test and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipeline(df):\n",
    "    # 1. Remove the duplicates\n",
    "    df = df[~df.duplicated()]\n",
    "    # 2. Normalize the Data\n",
    "    normalized_df = normalize_min_max(df)\n",
    "    # 3. Find and remove the outliers\n",
    "    final_data = outlier_removal(normalized_df.values)\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fitting and Transformation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we used the full `iris_data` dataset as a test. However, let's use our little pipeline on the training data and the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08823529, 0.66666667, 0.        , 0.04166667],\n",
       "       [0.41176471, 1.        , 0.0877193 , 0.125     ],\n",
       "       [0.70588235, 0.45833333, 0.59649123, 0.54166667],\n",
       "       [0.14705882, 0.58333333, 0.10526316, 0.04166667],\n",
       "       [0.02941176, 0.5       , 0.05263158, 0.04166667],\n",
       "       [0.58823529, 0.20833333, 0.70175439, 0.75      ],\n",
       "       [0.61764706, 0.5       , 0.61403509, 0.58333333],\n",
       "       [0.26470588, 0.625     , 0.0877193 , 0.04166667],\n",
       "       [0.20588235, 0.66666667, 0.07017544, 0.04166667],\n",
       "       [0.26470588, 0.875     , 0.0877193 , 0.        ],\n",
       "       [0.44117647, 0.29166667, 0.71929825, 0.75      ],\n",
       "       [0.5       , 0.58333333, 0.61403509, 0.625     ],\n",
       "       [0.70588235, 0.45833333, 0.64912281, 0.58333333],\n",
       "       [0.32352941, 0.79166667, 0.05263158, 0.125     ],\n",
       "       [0.32352941, 0.70833333, 0.0877193 , 0.04166667],\n",
       "       [0.35294118, 0.16666667, 0.47368421, 0.375     ],\n",
       "       [0.58823529, 0.33333333, 0.71929825, 0.58333333],\n",
       "       [0.61764706, 0.45833333, 0.78947368, 0.70833333],\n",
       "       [0.67647059, 0.41666667, 0.59649123, 0.54166667],\n",
       "       [0.85294118, 0.66666667, 0.89473684, 1.        ],\n",
       "       [0.41176471, 0.375     , 0.56140351, 0.5       ],\n",
       "       [0.97058824, 0.41666667, 0.98245614, 0.83333333],\n",
       "       [0.38235294, 0.41666667, 0.61403509, 0.58333333],\n",
       "       [0.23529412, 0.625     , 0.07017544, 0.04166667],\n",
       "       [1.        , 0.33333333, 1.        , 0.79166667],\n",
       "       [0.44117647, 0.29166667, 0.54385965, 0.375     ],\n",
       "       [0.26470588, 0.58333333, 0.07017544, 0.04166667],\n",
       "       [0.20588235, 0.625     , 0.05263158, 0.08333333],\n",
       "       [0.23529412, 0.75      , 0.15789474, 0.125     ],\n",
       "       [0.20588235, 0.        , 0.43859649, 0.375     ],\n",
       "       [0.58823529, 0.29166667, 0.68421053, 0.70833333],\n",
       "       [0.14705882, 0.58333333, 0.15789474, 0.04166667],\n",
       "       [0.20588235, 0.41666667, 0.10526316, 0.04166667],\n",
       "       [0.23529412, 0.54166667, 0.12280702, 0.16666667],\n",
       "       [0.38235294, 0.29166667, 0.56140351, 0.5       ],\n",
       "       [0.23529412, 0.58333333, 0.0877193 , 0.04166667],\n",
       "       [0.41176471, 0.41666667, 0.56140351, 0.45833333],\n",
       "       [1.        , 0.75      , 1.        , 0.875     ],\n",
       "       [0.08823529, 0.5       , 0.07017544, 0.04166667],\n",
       "       [0.55882353, 0.375     , 0.57894737, 0.5       ],\n",
       "       [0.41176471, 0.20833333, 0.70175439, 0.79166667],\n",
       "       [0.35294118, 0.91666667, 0.07017544, 0.04166667],\n",
       "       [0.5       , 0.41666667, 0.66666667, 0.70833333],\n",
       "       [0.5       , 0.08333333, 0.52631579, 0.375     ],\n",
       "       [0.32352941, 0.41666667, 0.61403509, 0.58333333],\n",
       "       [0.55882353, 0.58333333, 0.77192982, 0.91666667],\n",
       "       [0.35294118, 0.125     , 0.52631579, 0.5       ],\n",
       "       [0.32352941, 0.79166667, 0.12280702, 0.125     ],\n",
       "       [0.20588235, 0.125     , 0.40350877, 0.375     ],\n",
       "       [0.61764706, 0.29166667, 0.75438596, 0.75      ],\n",
       "       [0.20588235, 0.54166667, 0.07017544, 0.04166667],\n",
       "       [0.20588235, 0.5       , 0.03508772, 0.04166667],\n",
       "       [0.35294118, 0.16666667, 0.49122807, 0.41666667],\n",
       "       [0.70588235, 0.41666667, 0.70175439, 0.66666667],\n",
       "       [0.17647059, 0.45833333, 0.0877193 , 0.04166667],\n",
       "       [0.44117647, 0.33333333, 0.71929825, 0.95833333],\n",
       "       [0.20588235, 0.58333333, 0.0877193 , 0.04166667],\n",
       "       [0.20588235, 0.625     , 0.10526316, 0.20833333],\n",
       "       [0.47058824, 0.5       , 0.66666667, 0.70833333],\n",
       "       [0.23529412, 0.20833333, 0.35087719, 0.41666667],\n",
       "       [0.76470588, 0.5       , 0.8245614 , 0.91666667],\n",
       "       [0.5       , 0.29166667, 0.71929825, 0.625     ],\n",
       "       [0.52941176, 0.25      , 0.80701754, 0.54166667],\n",
       "       [1.        , 0.41666667, 0.89473684, 0.91666667],\n",
       "       [0.35294118, 0.20833333, 0.52631579, 0.5       ],\n",
       "       [0.02941176, 0.375     , 0.07017544, 0.04166667],\n",
       "       [0.        , 0.41666667, 0.01754386, 0.        ],\n",
       "       [0.5       , 0.08333333, 0.70175439, 0.58333333],\n",
       "       [0.85294118, 0.5       , 0.87719298, 0.70833333],\n",
       "       [0.08823529, 0.45833333, 0.0877193 , 0.04166667],\n",
       "       [0.23529412, 0.625     , 0.07017544, 0.08333333],\n",
       "       [0.02941176, 0.41666667, 0.05263158, 0.04166667],\n",
       "       [0.58823529, 0.20833333, 0.68421053, 0.58333333],\n",
       "       [0.58823529, 0.58333333, 0.80701754, 0.95833333],\n",
       "       [0.08823529, 0.58333333, 0.07017544, 0.08333333],\n",
       "       [0.73529412, 0.41666667, 0.78947368, 0.83333333],\n",
       "       [0.58823529, 0.54166667, 0.87719298, 1.        ],\n",
       "       [0.11764706, 0.5       , 0.05263158, 0.04166667],\n",
       "       [0.52941176, 0.375     , 0.64912281, 0.54166667],\n",
       "       [0.64705882, 0.33333333, 0.63157895, 0.58333333],\n",
       "       [0.55882353, 0.33333333, 0.66666667, 0.70833333],\n",
       "       [0.79411765, 0.5       , 0.64912281, 0.54166667],\n",
       "       [0.61764706, 0.5       , 0.75438596, 0.91666667],\n",
       "       [0.23529412, 0.75      , 0.10526316, 0.04166667],\n",
       "       [0.76470588, 0.45833333, 0.77192982, 0.83333333],\n",
       "       [0.47058824, 0.41666667, 0.56140351, 0.58333333],\n",
       "       [0.64705882, 0.41666667, 0.73684211, 0.79166667],\n",
       "       [0.41176471, 0.25      , 0.43859649, 0.375     ],\n",
       "       [0.26470588, 0.29166667, 0.50877193, 0.54166667],\n",
       "       [0.52941176, 0.41666667, 0.63157895, 0.54166667],\n",
       "       [0.05882353, 0.125     , 0.05263158, 0.08333333],\n",
       "       [0.67647059, 0.375     , 0.63157895, 0.5       ],\n",
       "       [0.35294118, 0.25      , 0.59649123, 0.45833333],\n",
       "       [0.29411765, 0.70833333, 0.0877193 , 0.04166667],\n",
       "       [0.38235294, 0.41666667, 0.54385965, 0.5       ],\n",
       "       [0.88235294, 0.375     , 0.92982456, 0.70833333],\n",
       "       [0.70588235, 0.54166667, 0.8245614 , 0.83333333],\n",
       "       [0.23529412, 0.70833333, 0.0877193 , 0.125     ],\n",
       "       [0.17647059, 0.16666667, 0.40350877, 0.375     ],\n",
       "       [0.70588235, 0.54166667, 0.8245614 , 1.        ],\n",
       "       [0.85294118, 0.41666667, 0.84210526, 0.625     ],\n",
       "       [0.17647059, 0.66666667, 0.07017544, 0.        ],\n",
       "       [0.70588235, 0.45833333, 0.80701754, 0.95833333],\n",
       "       [0.17647059, 0.41666667, 0.07017544, 0.04166667],\n",
       "       [0.76470588, 0.45833333, 0.68421053, 0.58333333],\n",
       "       [0.91176471, 0.33333333, 0.89473684, 0.75      ],\n",
       "       [0.58823529, 0.375     , 0.80701754, 0.70833333],\n",
       "       [0.41176471, 0.33333333, 0.54385965, 0.5       ],\n",
       "       [0.64705882, 0.41666667, 0.78947368, 0.70833333],\n",
       "       [0.58823529, 0.125     , 0.59649123, 0.5       ],\n",
       "       [0.61764706, 0.375     , 0.57894737, 0.5       ],\n",
       "       [0.38235294, 0.33333333, 0.68421053, 0.79166667],\n",
       "       [0.47058824, 0.41666667, 0.71929825, 0.70833333],\n",
       "       [0.32352941, 0.58333333, 0.12280702, 0.04166667],\n",
       "       [0.52941176, 0.33333333, 0.52631579, 0.5       ],\n",
       "       [0.17647059, 0.20833333, 0.61403509, 0.66666667],\n",
       "       [0.44117647, 0.83333333, 0.03508772, 0.04166667],\n",
       "       [0.44117647, 0.25      , 0.52631579, 0.45833333],\n",
       "       [0.82352941, 0.41666667, 0.85964912, 0.83333333]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the Training data\n",
    "train_df = pd.DataFrame(data=X_train, columns=iris.feature_names)\n",
    "transformed_train = data_pipeline(train_df)\n",
    "transformed_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4375    , 0.375     , 0.60714286, 0.5       ],\n",
       "       [0.3125    , 1.        , 0.07142857, 0.09090909],\n",
       "       [0.9375    , 0.25      , 1.        , 1.        ],\n",
       "       [0.40625   , 0.4375    , 0.57142857, 0.63636364],\n",
       "       [0.65625   , 0.375     , 0.625     , 0.59090909],\n",
       "       [0.21875   , 0.75      , 0.03571429, 0.13636364],\n",
       "       [0.28125   , 0.4375    , 0.41071429, 0.54545455],\n",
       "       [0.6875    , 0.5625    , 0.67857143, 1.        ],\n",
       "       [0.46875   , 0.        , 0.57142857, 0.63636364],\n",
       "       [0.34375   , 0.3125    , 0.46428571, 0.5       ],\n",
       "       [0.5625    , 0.625     , 0.67857143, 0.86363636],\n",
       "       [0.03125   , 0.5       , 0.01785714, 0.        ],\n",
       "       [0.25      , 0.8125    , 0.        , 0.04545455],\n",
       "       [0.0625    , 0.5625    , 0.03571429, 0.        ],\n",
       "       [0.125     , 1.        , 0.03571429, 0.09090909],\n",
       "       [0.5       , 0.6875    , 0.60714286, 0.68181818],\n",
       "       [0.5625    , 0.5       , 0.80357143, 0.95454545],\n",
       "       [0.28125   , 0.1875    , 0.46428571, 0.45454545],\n",
       "       [0.3125    , 0.375     , 0.57142857, 0.54545455],\n",
       "       [0.53125   , 0.375     , 0.76785714, 0.95454545],\n",
       "       [0.        , 0.625     , 0.05357143, 0.04545455],\n",
       "       [0.4375    , 0.5       , 0.64285714, 0.77272727],\n",
       "       [0.09375   , 0.75      , 0.05357143, 0.13636364],\n",
       "       [0.53125   , 0.375     , 0.76785714, 0.90909091],\n",
       "       [1.        , 1.        , 0.91071429, 0.86363636],\n",
       "       [0.625     , 0.5       , 0.69642857, 1.        ],\n",
       "       [0.625     , 0.1875    , 0.80357143, 0.77272727],\n",
       "       [0.65625   , 0.625     , 0.82142857, 1.        ],\n",
       "       [0.03125   , 0.5       , 0.01785714, 0.09090909],\n",
       "       [0.03125   , 0.5625    , 0.05357143, 0.04545455]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the pipeline to transform the test data (X_test)\n",
    "test_df = pd.DataFrame(data=X_test, columns=iris.feature_names)\n",
    "transformed_test = data_pipeline(test_df)\n",
    "transformed_test"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
